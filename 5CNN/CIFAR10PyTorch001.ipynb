{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquapathos/BasicAI/blob/master/5CNN/CIFAR10PyTorch001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=red>\n",
        "ランタイムメニューで「ランタイムのタイプを変更」を開き、「ハードウェアアクセラレータ」が <b>GPU</b> となっていることを確認してください。なっていないなら <b>GPU</b> に切り替え、次のセルを実行してください。</font>\n",
        "\n",
        "<font color=orange>無料ユーザの場合、GPUが使えないことが多くなっています。使えない場合は、時間がかかりますがCPUで実験を進めてください。</font>  \n",
        "\n",
        "メモ　最短で、CPUのみ45分、GPU35分\n",
        "\n",
        "次のセルを実行してください（▶マークをクリックするか、Shift＋Enter）\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AtTcwnMeBSCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "import datetime\n",
        "print(datetime.datetime.now())\n",
        "\n",
        "# 動作環境の確認\n",
        "import torch,os\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if device.type == 'cpu':\n",
        "  print('このランタイムはCPUのみです。GPUによる機械学習の高速化は利用できません。')\n",
        "  batch_size = 4 # バッチサイズ　データ数いくつごとにモデル修正するか\n",
        "  EPOCH = 5 #  # エポック（＝全データをモデル修正に１回ずつ使う）を5回繰り返す\n",
        "  EPOCH3 = 3 #  # model3用のエポック数\n",
        "  EXTEPOCH = 5 # model3 の追加学習\n",
        "  workers = 2 # 並列処理するときの並列実行の数\n",
        "else:\n",
        "  print(f'このランタイムはGPU {torch.cuda.get_device_name()}が利用可能です。')\n",
        "  os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"   # device side error が出る場合があるので同期を有効にしておく。（デバッグ用）\n",
        "  batch_size = 8 # バッチサイズ　データ数いくつごとにモデル修正するか\n",
        "  EPOCH = 5 # エポック（＝全データをモデル修正に５回ずつ使う）を５回繰り返す\n",
        "  EPOCH3 = 5 #  # model3用のエポック数\n",
        "  EXTEPOCH=10 # model3 の追加学習\n",
        "  workers = 1 # 並列処理するときの並列実行の数\n",
        "N_MID=64 # model3 の後半畳み込み層のノード数"
      ],
      "metadata": {
        "id": "eAVM9-ASRcur",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEfwOxDSdIL2"
      },
      "source": [
        "# CIFAR-10 にチャレンジ\n",
        "(参考）[CIFAR-10データセットの日本語による解説](https://atmarkit.itmedia.co.jp/ait/articles/2006/10/news021.html)\n",
        "\n",
        "## CIFAR-10\n",
        "\n",
        "![](https://pytorch.org/tutorials/_images/cifar10.png)\n",
        "\n",
        "CIFAR-10 はAlex Krizhevsky, Vinod Nair, Geoffrey Hinton によって収集された画像データセットで、画像認識のための機械学習の研究や学習でよく取り上げられます。\n",
        "\n",
        "このデータセットに集められている画像は、縦32×横32ピクセルという小さいカラー画像で、容量の小さいPCでも扱えるのが特徴です。\n",
        "\n",
        "CIFAR-10 には訓練用50000枚、テスト用10000枚、計60000枚の画像が含まれており、\n",
        "- airplane (飛行機)\n",
        "- automobile (自動車）\n",
        "- bird (鳥類）\n",
        "- cat （ネコ)\n",
        "- deer (シカ）\n",
        "- dog （イヌ）\n",
        "- frog （カエル）\n",
        "- horse（ウマ）\n",
        "- ship（船舶）\n",
        "- truck（トラック）\n",
        "\n",
        "のいずれかのラベルがつけられています。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipfDxuNghX10"
      },
      "source": [
        "# １．データの読み込みと確認\n",
        "　<font color=blue>次のセルを実行してください</font>　コードは非表示にしてありますが、必ず実行してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JDYnjbKtUe1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title  CIFAR10データセットの読み込み\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import warnings\n",
        "import numpy as np\n",
        "warnings.simplefilter('ignore', category=RuntimeWarning)\n",
        "\n",
        "TESTEPOCH = 1 # 動作確認のためのエポック数\n",
        "\n",
        "classesC10 = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# データ変換の定義　範囲[-1,+1]のテンソル表現への変換\n",
        "transform0 = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# CIFAR10の訓練用データとデータローダ\n",
        "trainsetC10 = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform = transform0)\n",
        "trainloaderC10 = torch.utils.data.DataLoader(trainsetC10, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=workers)\n",
        "# CIFAR10のテスト用データとデータローダ\n",
        "testsetC10 = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform = transform0)\n",
        "testloaderC10 = torch.utils.data.DataLoader(testsetC10, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=workers)\n",
        "\n",
        "# 画像を１枚表示する関数\n",
        "def t2np(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    return np.transpose(npimg, (1, 2, 0))\n",
        "\n",
        "# データローダからバッチ数分の画像を取り出す。\n",
        "dataiter = iter(trainloaderC10)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# 先頭の画像を表示\n",
        "plt.title(\"%s\" % classesC10[labels[0]])\n",
        "plt.imshow(t2np(images[0]))\n",
        "\n",
        "# １バッチ分の画像を並べて表示\n",
        "def plotchr(images,labels,tlabels=[]):\n",
        "    # sns.set_context(\"talk\")   # \"talk\" はタイトルの文字サイズ。　paper <  notebook <  talk <  poster の順にフォントサイズが大きくなる\n",
        "    low = (len(images)-1)//batch_size+1\n",
        "    for i,(image,label) in enumerate(zip(images,labels)):\n",
        "        clabel = classesC10[label]\n",
        "        image = t2np(image)\n",
        "        plt.subplot(1,batch_size,i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        if len(tlabels) > 0:\n",
        "          plt.title(f\"{clabel}/{classesC10[tlabels[i]]}\")\n",
        "        else:\n",
        "          plt.title(\"%s\" % clabel)\n",
        "        plt.imshow(image,cmap=plt.cm.gray_r)\n",
        "plt.figure(figsize=(10,4),dpi=100)\n",
        "plotchr(images,labels,tlabels=[])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9NWL3ewi7t9"
      },
      "source": [
        "# ２．ヘルパー関数の定義\n",
        "　<font color=blue>次のセルを実行してください。</font>　　コードは非表示にしてあります"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_I3UUXdhQyG"
      },
      "outputs": [],
      "source": [
        "#@title  ヘルパー関数の定義 train, recognitionResult\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter(log_dir=\"./logs\")\n",
        "\n",
        "# 学習ヘルパー関数\n",
        "# 学習の実行\n",
        "def train(model, dataloader, optimizer, epochs=EPOCH,lastepoch=0,label=\"loss\"):\n",
        "    model.train() # 学習モードにスイッチ\n",
        "    for epoch in range(lastepoch,epochs,1):  # 全データをEPOCH回学習に利用したら終わり\n",
        "        running_loss = 0.0\n",
        "        accuracy = 0\n",
        "        total = 0\n",
        "        r_total = 0\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            # データセットからバッチサイズ個分のデータ[inputs, labels]を取り出す。\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # すべての学習対象パラメータ（結合重み、しきい値）の微係数を０にセット\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(images) # 現モデルを使って出力を求める (forward)\n",
        "            predicted = torch.max(model(images),1)[1]\n",
        "            loss = nn.CrossEntropyLoss()(outputs, labels) # カテゴリカルクロスエントロピー誤差を計算\n",
        "            loss.backward() # パラメータを変数として誤差を偏微分(backward)\n",
        "            optimizer.step() # 誤差逆伝搬学習　誤差が減る方向にパラメータを修正 (optimize)\n",
        "\n",
        "            # 統計量の出力\n",
        "            running_loss += loss.item()\n",
        "            accuracy += (predicted == labels).sum().item() # 正解数を積算\n",
        "            total += labels.size(0) # 入力画像数を積算\n",
        "            r_total += labels.size(0) # 入力画像数の積算、1000バッチ区切りで０リセット\n",
        "            if i % 100 == 99:\n",
        "                ndata = len(dataloader.dataset)\n",
        "                writer.add_scalar(label+\"loss\", running_loss/r_total,epoch*ndata+total)\n",
        "                writer.add_scalar(label+\"acc\", accuracy/r_total,epoch*ndata+total)\n",
        "            if i % 1000 == 999:    # 1000 バッチごとに表示\n",
        "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss /r_total:.3f}  acc:{accuracy/r_total:.3f}  ({accuracy}/{r_total})')\n",
        "                running_loss = 0.0\n",
        "                accuracy = 0\n",
        "                r_total = 0\n",
        "\n",
        "    print('学習完了')\n",
        "\n",
        "# 結果分析用ヘルパー関数\n",
        "#from pandas.compat.numpy import np_datetime64_compat\n",
        "import pandas as pd\n",
        "# クロス集計\n",
        "def recognitionResult(model, dataloader, classes=[]):\n",
        "    model.eval() # 推論モードにスイッチ\n",
        "    NCAT = len(classes)\n",
        "    ct1 = np.zeros((NCAT,NCAT),np.int32) # 認識結果集計表\n",
        "    ndata = 0 #\n",
        "    for data in dataloader:\n",
        "      images, labels = data\n",
        "\n",
        "      # バッチごとに出力を求める\n",
        "      images = images.to(device)\n",
        "      outputs = torch.max(model(images),1)[1]\n",
        "\n",
        "      ndata += len(images)\n",
        "\n",
        "      labels = labels.cpu().numpy().astype(int)\n",
        "      outputs = outputs.cpu().numpy().astype(int)\n",
        "      for t, p in zip(labels, outputs):\n",
        "            ct1[t, p] += 1\n",
        "\n",
        "    crossT1 = pd.concat(\n",
        "        [ pd.DataFrame(classes,columns=['正解カテゴリ']),\n",
        "          pd.DataFrame(ct1,columns=classes)],axis=1)\n",
        "\n",
        "    # 正解率（行ごと 実カテゴリごと）\n",
        "    row_acc = []\n",
        "    for i in range(NCAT):\n",
        "        row_sum = ct1[i].sum()\n",
        "        if row_sum == 0:\n",
        "            row_acc.append(np.nan)\n",
        "        else:\n",
        "            row_acc.append(round(100 * ct1[i, i] / row_sum, 1))\n",
        "\n",
        "    crossT1['正解率'] = row_acc\n",
        "    crossT1 = crossT1.set_index('正解カテゴリ')\n",
        "\n",
        "    # ---- 全体正解率 ---------------------------------------------\n",
        "    total = ct1.sum(dtype=np.int64)   # オーバーフロー防止\n",
        "    correct = int(np.trace(ct1))\n",
        "\n",
        "    if total == 0:\n",
        "        print(\"正解率は算出できません（データがありません）\")\n",
        "    else:\n",
        "        overall_acc = round(100 * correct / total, 1)\n",
        "        print(f\"正解率は {overall_acc}%\")\n",
        "\n",
        "    return crossT1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW114f6djhMN"
      },
      "source": [
        "# ３．モデル定義\n",
        "\n",
        "\n",
        "![models0](https://user-images.githubusercontent.com/5820803/184133695-65687a01-f4b8-469f-ada9-016926254d73.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9VofovMeh4I"
      },
      "source": [
        "次の3つのモデルで機械学習と認識を試してみます。  \n",
        "1. model1 ３層の全結合層からなるバックプロパゲーションネットワーク\n",
        "2. model2 基本的なCNN（畳み込みニューラルネットワーク）\n",
        "3. model3 全結合層をGAP(グローバルアベレージプーリング）層で置き換えたCNN\n",
        "\n",
        "## (1) model1 ３層全結合モデル\n",
        "入力層は3072ノード、中間層16ノード、出力層10ノードとします。\n",
        "入力画像は32✕32画素で各画素がRGBの３成分を持ち、32✕32✕3＝3072バイトで表されますので、1つの画素の１つの色成分を１つのニューロンに対応付けます。\n",
        "\n",
        "出力の表現としては、出力とカテゴリを１：１に対応付けるワンホットエンコーディングを採用し、10ノードとします。  \n",
        "\n",
        "中間層は16としていますが、16と言う数に根拠はありませんので、この数を変えればもっとよい結果が得られるかもしれません。ぜひチャレンジしてみてください。\n",
        "\n",
        "## 参考　出力とカテゴリの対応付け方法\n",
        "##### **数値エンコーディング(numeric encoding)**\n",
        "　　各カテゴリに１つの数値を割り当てる。出力ノードは１つでよい。\n",
        "##### **バイナリエンコーディング(binary encoding)**  \n",
        "　　各カテゴリに１つの２進表現を割り当てる。出力ノード数は2進表現の桁数。  \n",
        "##### **ワンホットエンコーディング (one hot encoding)**    \n",
        "　　カテゴリに１つにノードを１つ対応付ける。出力ノード数はカテゴリ数に一致する。\n",
        "\n",
        " >| カテゴリ|数値エンコーディング | バイナリエンコーディング|ワンホットエンコーディング|  \n",
        " |:---:|:---:|:---:|:---:|\n",
        " |ネコ|0|0 0|1 0 0 0|\n",
        " |イヌ|1|0 1|0 1 0 0|  \n",
        " |家|2|1 0|0 0 1 0|\n",
        " |車|3|1 1|0 0 0 1|\n",
        "||||\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "　<font color=blue>次のセルを実行してください</font>  コードは非表示にしてあります\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTEjnedHho3M",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title model1\n",
        "# model1\n",
        "class Model1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        n_in = 32,\n",
        "        self.fc1 = nn.Linear(3*32*32, 16)  # 3x32x32=3072 -> 10\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(16, 10)  # 3x32x32=3072 -> 10\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1) #3x32x32\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model1 = Model1()\n",
        "model1 = model1.to(device)\n",
        "\n",
        "optimizer1 = optim.SGD(model1.parameters(), lr=0.001, momentum=0.9) # SGD（確率的勾配降下法）\n",
        "#optimizer = optim.Adam(model1.parameters(), lr=0.001) #\n",
        "\n",
        "# モデル概要\n",
        "summary(model1,(3,32,32))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Total paras: 49,338**  \n",
        "と表示されていることに注目してください。\n",
        "これは、このニューラルネットワークに約5万の調整可能なパラメータがあることを意味しています。数学的に言うと、このモデルの正解率を最大化するという問題は、５万次元の最適化問題であることを意味します。"
      ],
      "metadata": {
        "id": "_pmtpFHd1322"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2) model2  基本的なCNN（畳み込みニューラルネットワーク）\n",
        "\n",
        "PyTorchの公式サイトの識別器のプログラムのチュートリアル、[TRAINING A CLASSIFIER](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) に掲載されているモデルです。\n",
        "\n",
        "畳み込み層が２つ、プーリング層が２つ、全結合層が３つで構成されています。必要最小限の典型的なCNNのモデルと言えるでしょう。\n",
        "\n",
        "1. 6チャネル、カーネルサイズ５の畳み込み層とプーリング層\n",
        "2. 16チャネル、カーネルサイズ16の畳み込み層とプーリング層\n",
        "3. 3層の全結合層　第1中間層のノード数120、第２中間層のノード数84\n",
        "\n",
        "から成る、最小構成の、典型的な畳み込みニューラルネットワークです。深層学習としてはほぼ最小構成ですが、結構高いパフォーマンスを示します。\n",
        "\n",
        "このネットワークも、チャネル数、全結合層のノード数は、これが最適であるという根拠はありませんし、実際に最適ではありません。\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<font color=blue>次のセルを実行してください</font>  コードは非表示にしてあります\n"
      ],
      "metadata": {
        "id": "7bbIYpgvmAN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title model2\n",
        "# PyTorch チュートリアル掲載モデル\n",
        "class Model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x) # 3x32x32 -> 6x28x28\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)  # 6x28x28 -> 6x14x14\n",
        "        x = self.conv2(x) # 6x14x14 -> 16x10x10\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)  # 16x10x10 -> 16x5x5\n",
        "        x = torch.flatten(x, 1) # 16x5x5 -> 400\n",
        "        # あるいは、x = x.view(-1,400) # 16x5x5 -> 400\n",
        "        x = self.fc1(x) # 400 -> 120\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x) # 120 -> 84\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x) # 84 -> 10\n",
        "        return x\n",
        "\n",
        "model2 = Model2()\n",
        "model2 = model2.to(device)\n",
        "\n",
        "optimizer2 = optim.SGD(model2.parameters(), lr=0.001, momentum=0.9) # SGD（確率的勾配降下法）\n",
        "#optimizer = optim.Adam(model1.parameters(), lr=0.001) #\n",
        "\n",
        "# モデル概要\n",
        "summary(model2,(3,32,32))"
      ],
      "metadata": {
        "id": "k8XOAKr01c1p",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "パラメータ数は約６万２千ですが、その大部分は Linear、つまり全結合層のパラメータです。計算量はパラメータ数に比例すると考えられるので、CNNにおいて畳み込み層の計算量は、そのノード数に比して相対的に小さいことがわかります。"
      ],
      "metadata": {
        "id": "tDxFn1WjPxNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (3) model3  全結合層をGAP(グローバルアベレージプーリング）層で置き換えたCNN\n",
        "\n",
        "model2 からの変更点は以下の通りです。\n",
        "- 畳み込み層を２つ増やす。ただし、カーネルサイズを５から３に減らしてある。\n",
        "- 全結合層をなくし、GAP（Global Average Pooling）に置き換える。\n",
        "- 畳み込み層のノード数を大きく増やした。6,16 -> 64,128,128,128\n",
        "- 活性化関数を ReLU からFReLU に変更。\n",
        "- オプティマイザを SGD から Adam に変更\n",
        "\n",
        "## 解説\n",
        "**GAP(Global Average Pooling)**   \n",
        "１つのチャネル（例えば画像の赤色成分）を、そのチャネルに含まれるノード出力の平均値という１つの値で代表させるという処理を意味します。\n",
        "\n",
        "**プーリング**というのは、画像をNxN画素ごとに区切って、そのNxN個のノードをそれらの出力の平均値に置き換えていく操作です。その区切りサイズＮを最大限に大きくとって画像サイズに一致させた場合がGAPです。\n",
        "\n",
        "model2で示したように、CNNでは最後に全結合の層を3～4層設けるのが定番ですが、これをGAPで置き換えてもパフォーマンスは大きく損なわれないということが経験的にわかってきています。\n",
        "\n",
        "全結合層のパラメータ数は非常に膨大な数になりますが、それをGAPで置き換えるとパラメータ数は数十分の１となり、計算量を大きく削減できます。\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<font color=blue>次のセルを実行してください</font>\n"
      ],
      "metadata": {
        "id": "2gcvdB9AOjcI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdeTbOwis7KL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title model3\n",
        "class FReLU(nn.Module):\n",
        "    def __init__(self, in_c, k=3, s=1, p=1):\n",
        "        super().__init__()\n",
        "        self.f_conv = nn.Conv2d(in_c, in_c, kernel_size=k,stride=s, padding=p,groups=in_c)\n",
        "        self.bn = nn.BatchNorm2d(in_c)\n",
        "\n",
        "    def forward(self, x):\n",
        "        tx = self.bn(self.f_conv(x))\n",
        "        out = torch.max(x,tx)\n",
        "        return out\n",
        "\n",
        "class Model3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.n_mid = N_MID\n",
        "        self.conv1 = nn.Conv2d(3,6, 3,padding=1, padding_mode='replicate')\n",
        "        self.frelu = FReLU(6)\n",
        "        self.conv2 = nn.Conv2d(6,16,3, padding=1,padding_mode='replicate')\n",
        "        self.frelu1 = FReLU(16)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv3  = nn.Conv2d(16, self.n_mid, 3, padding=1,padding_mode='replicate')\n",
        "        self.frelu2 = FReLU(self.n_mid)\n",
        "        self.conv4  = nn.Conv2d(self.n_mid, self.n_mid, 3,padding=1, padding_mode='replicate')\n",
        "        self.frelu3 = FReLU(self.n_mid)\n",
        "        self.gavg = nn.AvgPool2d(8) # グローバルアベレージプーリング\n",
        "        self.layer = nn.Linear(self.n_mid, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x) # 3ch -> 6  3x3フィルタで畳み込み 32x32->32x32\n",
        "        x = self.frelu(x)\n",
        "        x = self.conv2(x) # 6ch -> 16  3x3フィルタで畳み込み 32x32 -> 32x32\n",
        "        x = self.frelu1(x)\n",
        "        x = self.pool(x)  # max pooling  2x2  32x32->16x16\n",
        "        x = self.conv3(x) # 16ch -> n_mid ch 3x3フィルタで畳み込み 16x16 -> 16x16\n",
        "        x = self.frelu2(x)\n",
        "        x = self.conv4(x) # n_mid ch -> n_mid ch 3x3フィルタで畳み込み 16x16 -> 16x16\n",
        "        x = self.frelu3(x)\n",
        "        x = self.pool(x)  # max pooling  2x2  16x16->8x8\n",
        "        x = self.gavg(x)  # n_midノード\n",
        "        x = x.view(-1,self.n_mid)\n",
        "        x = self.layer(x) # n_mid->10\n",
        "        return x\n",
        "\n",
        "\n",
        "''' # 時間に余裕があるなら、こちらの方がよい結果が得られる\n",
        "class Model3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 3,padding=1, padding_mode='replicate')\n",
        "        self.frelu = FReLU(64)\n",
        "        self.relu = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(64,128,3, padding=1,padding_mode='replicate')\n",
        "        self.frelu1 = FReLU(128)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv3  = nn.Conv2d(128, 128, 3, padding=1,padding_mode='replicate')\n",
        "        self.frelu2 = FReLU(128)\n",
        "        self.conv4  = nn.Conv2d(128, 128, 3,padding=1, padding_mode='replicate')\n",
        "        self.frelu3 = FReLU(128)\n",
        "        self.gavg = nn.AvgPool2d(8) # グローバルアベレージプーリング\n",
        "        self.layer = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x) # 3ch -> 64ch  3x3フィルタで畳み込み 32x32->32x32\n",
        "        x = self.frelu(x)\n",
        "        x = self.conv2(x) # 64ch ->128ch  3x3フィルタで畳み込み 32x32 -> 32x32\n",
        "        x = self.frelu1(x)\n",
        "        x = self.pool(x)  # max pooling  2x2  32x32->16x16\n",
        "        x = self.conv3(x) # 128ch -> 128ch 3x3フィルタで畳み込み 16x16 -> 16x16\n",
        "        x = self.frelu2(x)\n",
        "        x = self.conv4(x) # 128ch -> 128ch 3x3フィルタで畳み込み 16x16 -> 16x16\n",
        "        x = self.frelu3(x)\n",
        "        x = self.pool(x)  # max pooling  2x2  16x16->8x8\n",
        "        x = self.gavg(x)  # 128ノード\n",
        "        x = x.view(-1,128)\n",
        "        x = self.layer(x) # 128->10\n",
        "        return x\n",
        "'''\n",
        "\n",
        "model3 = Model3()\n",
        "model3.to(device)\n",
        "\n",
        "#optimizer3 = optim.SGD(model3.parameters(), lr=0.001, momentum=0.9) # SGD（確率的勾配降下法）\n",
        "optimizer3 = optim.Adam(model3.parameters(), lr=0.001) #\n",
        "\n",
        "# モデル概要\n",
        "summary(model3,(3,32,32))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "パラメータ数はおよそ５万です。モデルはmodel1,model2と比べて複雑になっていますが、パラメータ数は大差ありません。"
      ],
      "metadata": {
        "id": "PcgbGSU4ogt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ４．学習\n",
        "\n",
        "## (1) model1\n",
        "\n",
        "#### 動作確認　　<font color=blue>次のセルを実行してください</font>"
      ],
      "metadata": {
        "id": "hUK7ZXV18IbK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "print(\"動作確認\")\n",
        "train(model=model1, dataloader=trainloaderC10,optimizer=optimizer1, epochs=TESTEPOCH, label=\"model1\")"
      ],
      "metadata": {
        "id": "PtgFeNbUji1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [1, 6000]  1はエポック数　全データを1回学習に使うことを１エポックと言います。１は1回目という意味。1000,2000,…,6000はバッチ学習回数、このプログラムでは、GPUの場合8データ分を1バッチとし、バッチごとにモデルのパラメータを更新します。CIFAR10の学習データは5万個あるので、1エポックは6250バッチになります。（CPUの場合は４データを1バッチとしているので、1エポックは12500バッチ）\n"
      ],
      "metadata": {
        "id": "RiEiTdrR4aY3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **loss** 平均誤差（クロスエントロピー誤差）**acc** 正解率　です。    \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<font color=blue>次のセルを実行してください</font> さきほどの続きで、２エポック目からトータル５エポック学習させてみます。\n",
        "\n",
        "<font color=red>（注意）学習(train)は２度実行すると追加学習となります。やり直す場合は、モデル定義のセルからやり直してください.</font>"
      ],
      "metadata": {
        "id": "h7-IaKKekkkj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUROkQ12huRg"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train(model=model1, dataloader=trainloaderC10,optimizer=optimizer1, epochs=EPOCH, lastepoch=TESTEPOCH, label=\"model1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model1 正解率 クロス集計\n",
        "\n",
        "### (model1-1) 訓練データに対する正解率　<font color=blue>次のセルを実行してください</font>"
      ],
      "metadata": {
        "id": "zVthVEPultRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#@title　model1 正解率（訓練データ）\n",
        "trainct1 = recognitionResult(model1,trainloaderC10,classes=classesC10)"
      ],
      "metadata": {
        "id": "3IvOAsEXmMc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　model1 クロス集計（訓練データ）\n",
        "trainct1"
      ],
      "metadata": {
        "id": "HN0HPUye9HAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### (model1-2) テストデータに対する正解率"
      ],
      "metadata": {
        "id": "9larABpGzz66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#@title　model1 正解率（テストデータ）\n",
        "testct1 = recognitionResult(model1,testloaderC10,classes=classesC10)"
      ],
      "metadata": {
        "id": "OD0Lp7XempAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "結果を清書します。<font color=blue>次のセルを実行してください</font>"
      ],
      "metadata": {
        "id": "50FS4qYU9BIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　model1 クロス集計（テストデータ）\n",
        "testct1"
      ],
      "metadata": {
        "id": "9RQmej_u9CUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "正解率は訓練データで4割後半、テストデータで4割前半ぐらいになるはずです。"
      ],
      "metadata": {
        "id": "9hSMYNW5m8eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (2) model2\n",
        "一気に学習させてみましょう。<font color=blue>次のセルを実行してください</font>"
      ],
      "metadata": {
        "id": "-9d5phC4pYiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train(model=model2, dataloader=trainloaderC10,optimizer=optimizer2, epochs=EPOCH, lastepoch=0, label=\"model2\")"
      ],
      "metadata": {
        "id": "P8CwQeBUpXFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model 2 正解率　クロス集計\n",
        "### (model2-1) 訓練データに対する正解率\n",
        "<font color=blue>次のセルを実行してください</font>"
      ],
      "metadata": {
        "id": "fjqUanhtv68L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#@title　model2 正解率（訓練データ）\n",
        "trainct2 = recognitionResult(model2,trainloaderC10,classes=classesC10)"
      ],
      "metadata": {
        "id": "rxeHdBNMvOaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "結果を清書します。<font color=blue>次のセルを実行してください</font>"
      ],
      "metadata": {
        "id": "Scel-4fX88LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　model2 クロス集計（訓練データ）\n",
        "trainct2"
      ],
      "metadata": {
        "id": "65DWLM6M89D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (model2-2) テストデータに対する正解率\n",
        "<font color=blue>次のセルを実行してください</font>"
      ],
      "metadata": {
        "id": "vhp3n6nQv9mE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#@title　model2 正解率（テストデータ）\n",
        "testct2 = recognitionResult(model2,testloaderC10,classes=classesC10)"
      ],
      "metadata": {
        "id": "zGoAJvQBrVKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "結果を清書します。<font color=blue>次のセルを実行してください</font>"
      ],
      "metadata": {
        "id": "Y0kr8BjO82h4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　model2 クロス集計（テストデータ）\n",
        "testct2"
      ],
      "metadata": {
        "id": "g9YGMh2C81kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "このモデルでは正解率が訓練用、テスト用ともに６割を超えるぐらいになるはずです。\n",
        "\n",
        "## (3) model3\n",
        "<font color=blue>次のセルを実行してください</font>\n",
        "\n"
      ],
      "metadata": {
        "id": "kiUgd4mFpWzF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhLUvWj5ehHc"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "train(model=model3, optimizer=optimizer3, dataloader=trainloaderC10, epochs=EPOCH3, lastepoch=0,label=\"model3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model3は時間がかかるのでエポック数を少なくしています。"
      ],
      "metadata": {
        "id": "CgV8qWe7DrY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# model3 正解率　クロス集計\n",
        "### (model3-1) 訓練データに対する正解率\n",
        "<font color=blue>次のセルを実行してください</font>"
      ],
      "metadata": {
        "id": "na_FsWXRzhzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#@title　model3 正解率（訓練データ）\n",
        "trainct3 = recognitionResult(model3,trainloaderC10,classes=classesC10)"
      ],
      "metadata": {
        "id": "2KQMY17Z1Az1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "結果を清書します。<font color=blue>次のセルを実行してください</font>"
      ],
      "metadata": {
        "id": "NitVLyrA8ZBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　model3 クロス集計（訓練データ）\n",
        "trainct3"
      ],
      "metadata": {
        "id": "L4CNF1xk8ZxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (model3-2) テストデータに対する正解率\n",
        "<font color=blue>次のセルを実行してください</font>\n"
      ],
      "metadata": {
        "id": "e9TPdipkzjBx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPB4uYvgFX0e"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "#@title　model3 正解率（テストデータ）\n",
        "testct3 = recognitionResult(model3,testloaderC10,classes=classesC10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "結果を清書します。<font color=blue>次のセルを実行してください</font>"
      ],
      "metadata": {
        "id": "nLC-fWl28m_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　model3 クロス集計（テストデータ）\n",
        "testct3"
      ],
      "metadata": {
        "id": "x3YQws0g8oVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model3 の正解率は訓練用、テスト用どちらのデータでも、３エポックで7割、５エポックで8割前後になります。"
      ],
      "metadata": {
        "id": "865Rqpjg1jUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=red>学習済みモデルの保存\n",
        "<font color=red>次の実験に必要となりますので、次のセルを実行して学習済みモデルを保存してください。\n",
        "\n",
        "これをやらないと、ここまでの実験をもう一度やり直さないといけなくなります。</font>"
      ],
      "metadata": {
        "id": "gZMfie_f1WhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 手順１　Google Drive との接続\n",
        "Google Drive のマウント\n",
        "\n",
        "1. <font color='blue'>この説明の下のセルを実行する\n",
        "2. アクセス許可の確認ダイアログが出る。「Googleドライブに接続」をクリック。\n",
        "3. アカウントを選択する。\n",
        "4. アクセスリクエストのダイアログに変わる。一番下までスクロールし「許可」をクリック。"
      ],
      "metadata": {
        "id": "Ng3-h67Q6rBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "LFVarHLq6eN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 手順2　Google Drive内に保存\n",
        "Google Drive 内に学習済みモデルを保存します。\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<font color=blue>次のセルを実行してください</font>"
      ],
      "metadata": {
        "id": "rUWlrOMY7sYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title   学習済みモデルの保存\n",
        "FNAME = 'model3.pth'\n",
        "DIR = '/content/drive/MyDrive/CIFAR10'\n",
        "GPUPATH = f\"{DIR}/gpu_{N_MID}_{FNAME}\"\n",
        "CPUPATH = f\"{DIR}/cpu_{N_MID}_{FNAME}\"\n",
        "if not os.path.exists(DIR):\n",
        "  os.makedirs(DIR)\n",
        "torch.save(model3.to('cpu').state_dict(), CPUPATH)\n",
        "if device.type == 'cuda':\n",
        "  torch.save(model3.state_dict(), GPUPATH)\n",
        "model3 = model3.to(device)"
      ],
      "metadata": {
        "id": "1ZredQirU2HQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Drive の CIFAR10フォルダに\n",
        "- gpu_64_model3.pth  - GPUが使える環境用の学習済みモデル\n",
        "- cpu_64_model3.pth  - GPUが使えない環境用の学習済みモデル\n",
        "が保存されます。\n"
      ],
      "metadata": {
        "id": "Pf9z5tkcVFTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**以下を実行して，時刻を記録してください。**"
      ],
      "metadata": {
        "id": "Iz5sHZxKYZJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(datetime.datetime.now())"
      ],
      "metadata": {
        "id": "WVA5K78F_eTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 学習曲線の確認\n",
        "\n",
        "<font color=blue>次のセルを実行してください</font>\n",
        "\n",
        "表示には少し時間がかかります。"
      ],
      "metadata": {
        "id": "PllB1PDu2B9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "7BSiBY9u1ypP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img width=\"442\" alt=\"5epoch\" src=\"https://user-images.githubusercontent.com/5820803/184563227-7ca463c9-766e-4a8e-8a65-aa48c314af31.png\">\n",
        "\n",
        "loss が０、acc は1が最適（全問正解）を意味します。グラフを見ると model3 は 5 EPOCHは、追加学習でもっとよくなりそうです。ちなみに、1epoch とは、全データをもれなく1度ずつ学習に使うことで、CIFAR-10なら５epochで25万回識別を試みたことになります。\n",
        "\n",
        "次の演習で model3 を使いますので、<font color=blue>時間があれば、次のセルを実行して、model3 の追加学習を行ってください。</font>"
      ],
      "metadata": {
        "id": "PbYR8r7W2pJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 追加学習\n",
        "\n",
        "下のコードを実行すると、model3 を、CPUで2エポック、GPUで5エポック追加学習できます。<font color=red>10分程度時間がかかります。正解率は上がりますが、途中でやめて時間をおいて続きをやるということができませんので、時間に余裕がない場合は、ここで実験を打ち切ってください。</font>\n"
      ],
      "metadata": {
        "id": "zvzUPHgSHgdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model3 = model3.to(device)\n",
        "train(model=model3, optimizer=optimizer3, dataloader=trainloaderC10, epochs=EXTEPOCH, lastepoch=EPOCH3,label=\"model3\")\n"
      ],
      "metadata": {
        "id": "-313TI_w3mv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "追加学習した場合は、正解率の改善を確認しましょう"
      ],
      "metadata": {
        "id": "kl6KEt77AyuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　model3 正解率（訓練データ　追加学習後）\n",
        "trainct3 = recognitionResult(model3,trainloaderC10,classes=classesC10)"
      ],
      "metadata": {
        "id": "-lpg_XMXAmhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　model3 クロス集計（訓練データ　追加学習後）\n",
        "trainct3"
      ],
      "metadata": {
        "id": "2kQFLlLMAGVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　model3 正解率（テストータ　追加学習後）\n",
        "testct3 = recognitionResult(model3,testloaderC10,classes=classesC10)"
      ],
      "metadata": {
        "id": "6RrPN4tTAa7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　model3 クロス集計（テストデータ　追加学習後）\n",
        "testct3"
      ],
      "metadata": {
        "id": "MQoAP9n_AJXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "追加学習を実施した場合は、次のセルを実行して学習済みモデルを更新して下さい。"
      ],
      "metadata": {
        "id": "mcq7f9JB7Cbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "if not os.path.exists(DIR):\n",
        "  os.makedirs(DIR)\n",
        "torch.save(model3.to('cpu').state_dict(), CPUPATH)\n",
        "if device.type == 'cuda':\n",
        "  torch.save(model3.state_dict(), GPUPATH)\n",
        "model3 = model3.to(device)"
      ],
      "metadata": {
        "id": "qHqKhcMs7BsV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "再び学習曲線を確認します。"
      ],
      "metadata": {
        "id": "3eLBV-TcY4Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "nCFH1HyZY5dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**以上で演習は終わりです。最後に以下を実行して，時刻を記録してください。**"
      ],
      "metadata": {
        "id": "D-gaQOiU9Y2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(datetime.datetime.now())"
      ],
      "metadata": {
        "id": "_XYYpLHY5_jL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}