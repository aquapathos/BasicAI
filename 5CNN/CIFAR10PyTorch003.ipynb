{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquapathos/BasicAI/blob/master/5CNN/CIFAR10PyTorch003.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "CIFAR10PyTorch001, CIFAR10PyTorch002 が完了していることを前提としています。まだの人は先に済ませてください。"
      ],
      "metadata": {
        "id": "dfoHUIzyaWFi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lraSof5Dlv83"
      },
      "source": [
        "# 1. 準備\n",
        "## 1.1 ハードウェアアクセラレータの設定\n",
        "\n",
        "1. 「CIFAR10PyTorch001, CIFAR10PyTorch002」を済ませておく\n",
        "2. [「ランタイム」メニューを開く]()\n",
        "3. [「ランタイムのタイプを変更」をクリック]()\n",
        "4. [[「ハードウェアアクセラレータ」で **GPU** を選択し，「保存」]()\n",
        "\n",
        "<font color='green'>※ Google Colabは無料サービスを維持するため、利用者が多すぎるため GPU が使えない場合があります。その場合は時間がかかりますが、CPUでも実験は可能です。    \n",
        "※ 同様に、複数セッションが許可されない場合があります。「セッションが多すぎます」と出た場合は他の起動中ランタイムを終了させてください。</font>\n",
        "\n",
        "[次のセルを実行してください]() 　コードは非表示にしてあります。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 動作環境の確認\n",
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "N_MID=64\n",
        "print(device)\n",
        "if device.type != 'cpu':\n",
        "  print(torch.cuda.get_device_name())\n",
        "  print(torch.cuda.get_device_capability())"
      ],
      "metadata": {
        "id": "2lWDBREzk2rU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D_x2m9coOKC"
      },
      "source": [
        "## 1.2  Google Drive をマウント\n",
        "AIChallenge001 で保存した画像データを使うために Google Drive に接続します。\n",
        "\n",
        "1. <font color='blue'>この説明の下のセルを実行する\n",
        "2. アクセス許可の確認ダイアログが出る。「Googleドライブに接続」をクリック。\n",
        "3. アカウントを選択する。\n",
        "4. アクセスリクエストのダイアログに変わる。一番下までスクロールし「許可」をクリック。\n",
        "5. 左のファイル一覧エリアで「更新アイコン」（回転マーク）をクリック（エリアが表示されていないなら「ファイルアイコン」（フォルダ型）をクリック）\n",
        "6. しばらく待つと drive という名のフォルダが現れます。</font>\n",
        "\n",
        "<img width=\"390\" alt=\"googlecolab\" src=\"https://user-images.githubusercontent.com/5820803/94802343-739cff00-0422-11eb-8c0d-affa919f8e58.png\">\n",
        "\n",
        "\n",
        "　[次のセルを実行してください]()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISH2fMainqnu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ7Cr-AupBM7"
      },
      "source": [
        "## 1.3 表示用ヘルパー関数の定義\n",
        "002 で定義したのと同じ関数を読み込みます。　[次のセルを実行してください]() （コードは非表示にしてありますが実行できます。興味があるなら表示しても構いません。）\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!pip -q install japanize-matplotlib\n",
        "import pickle\n",
        "import os,math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import japanize_matplotlib\n",
        "\n",
        "# pickle 形式で保存された画像データの読み込み\n",
        "def loadCategoryImages(fname, folder = \".\"):\n",
        "    f = open(folder+\"/\"+fname,'rb')\n",
        "    cat = pickle.load(f)\n",
        "    f.close\n",
        "    return cat\n",
        "\n",
        "# start番からnpic枚表示する関数を定義\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (12.0, 7.0)\n",
        "def showimg(images, start = 0, npic = 48):\n",
        "    n = npic if len(images) >= start+npic else len(images) - start\n",
        "    plt.figure(figsize=(8,7.5*(math.ceil(n/8))/6),dpi=150)\n",
        "    i = 0\n",
        "    while True:\n",
        "        if i < n :\n",
        "            plt.subplot((n-1)//8+1,8,i+1)\n",
        "            plt.xticks([])\n",
        "            plt.yticks([])\n",
        "            plt.imshow(images[start+i])\n",
        "            plt.title(\"{}\".format(start+i))\n",
        "            i += 1\n",
        "        else:\n",
        "            break"
      ],
      "metadata": {
        "id": "C-zZoJyCfcso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 独自データセットの作成\n",
        "## 2.1 画像データの復元\n"
      ],
      "metadata": {
        "id": "SKdNW3gpmx8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive からの画像の読み出し\n",
        "\n",
        "002で集めた画像を読み込みましょう。  \n",
        "<font color= blue>\n",
        "次のセルの **myclasses = ['ネコ','イヌ','灯台','スクータ']**  を自分の選んだカテゴリに書き換えてから実行してください。</font>\n",
        "\n",
        "<img width=\"234\" alt=\"yourimages\" src=\"https://user-images.githubusercontent.com/5820803/184477244-df5ded39-9474-408c-93c1-774b846456d0.png\">\n"
      ],
      "metadata": {
        "id": "_FVk-rmRf4nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myclasses = ['ネコ','イヌ','灯台','スクータ']\n",
        "GFOLDER = \"drive/MyDrive/CIFAR10\"  # データ保存用のフォルダ名\n",
        "myimages = {'classes':myclasses}\n",
        "for c in myclasses:\n",
        "  myimages[c] = loadCategoryImages(f\"{c}.pkl\", folder=GFOLDER)\n",
        "  showimg(myimages[c],0,8)"
      ],
      "metadata": {
        "id": "N7cvNHMRgCWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 自分で集めた画像でデータセットを作成する\n",
        "\n",
        "自分で収集した画像を使って次の３つのデータセットを作ります。\n",
        "\n",
        "1. **trainset**   訓練用データセット\n",
        "2. **testset**    テスト用データセット\n",
        "3. **catset**     ネコ画像のみからなるデータセット\n",
        "\n",
        "- 画像の枚数は一番枚数の少ないカテゴリに合わせることにします。\n",
        "- 画像全体の3分の2を使って訓練用、残りでテスト用のデータセットを作成します。\n",
        "- 訓練用とテスト用のデータセットは、各カテゴリが均等に含まれるようにします。\n",
        "\n",
        "　[次のセルを実行してください]() 　コードは非表示にしてあります。\n"
      ],
      "metadata": {
        "id": "YMStir06mbPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　データセットの作成\n",
        "# ライブラリのインポート\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchsummary import summary\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "#  自分で集めた画像データで訓練用とテスト用に分割する\n",
        "def make_datasetdata(myimages):\n",
        "    # catlist で与えられた画像データのリストから訓練用とテスト用のデータを作成し，\n",
        "    # Xtrain (訓練用画像), ytrain（訓練例の正解)，Xtrain (テスト用画像), ytrain（テスト画像に対する)，NDATA（1カテゴリ当たりのデータ数）\n",
        "    # 学習に用いるデータ数を、一番データ数の少ないカテゴリのデータ数に合わせる\n",
        "    classes = myimages['classes']\n",
        "    mindata = np.inf # 十分大きな数\n",
        "    for c in classes:\n",
        "        if len(myimages[c]) < mindata:\n",
        "            mindata = len(myimages[c])\n",
        "    # ここに到達した時点で、mindata にはもっともデータ数の少ないカテゴリのデータ数が入っている\n",
        "    NDATA = mindata\n",
        "    threer = mindata%3\n",
        "    NDATA = mindata - threer  #  個数を３の倍数となるよう調整\n",
        "\n",
        "    Xtrain,Xtest = [],[]  # 入力画像のリスト\n",
        "    ytrain,ytest = [],[]  #  ラベルのリスト\n",
        "    label = 0\n",
        "    for c in classes:\n",
        "        Xtrain = Xtrain + myimages[c][0:int(2*NDATA/3)]\n",
        "        ytrain = ytrain + [label]*int(2*NDATA/3)\n",
        "        Xtest = Xtest + myimages[c][int(2*NDATA/3):NDATA]\n",
        "        ytest = ytest + [label]*int(NDATA/3)\n",
        "        label +=1\n",
        "    return np.array(Xtrain),np.array(ytrain),np.array(Xtest),np.array(ytest),NDATA\n",
        "\n",
        "Xtrain,ytrain,Xtest,ytest,NDATA = make_datasetdata(myimages=myimages)\n",
        "print(f'訓練用計{len(ytrain)}枚,テスト用計{len(ytest)}枚')\n",
        "\n",
        "# データ変換の定義　範囲[-1,+1]のテンソル表現への変換  // 仕様変更により Resize に antialias=True を追加 2023.8.22\n",
        "transforms0 =  transforms.Compose(  # 正規化のみ\n",
        "    [transforms.ToTensor(),transforms.Resize((32,32),antialias=True),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "'''\n",
        "transforms1 = transforms.Compose(   # アフィン変換＋色調変換＋ランダムな左右反転による画像水増し\n",
        "    [\n",
        "     transforms.ToTensor(),\n",
        "     transforms.RandomAffine(degrees=[-5, 5], translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "     transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.Resize((32,32)),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "'''\n",
        "# 独自データセットのクラス定義\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data,labels, transforms):\n",
        "        super().__init__()\n",
        "        self.transforms = transforms\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self,index: int):\n",
        "        data = self.data[index]\n",
        "        label = self.labels[index]\n",
        "        # データの変形 (transforms)\n",
        "        data = self.transforms(data)\n",
        "        return data, label\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "trainset = MyDataset(Xtrain,ytrain,transforms0)\n",
        "# trainset1 = MyDataset(Xtrain,ytrain,transforms1)\n",
        "testset = MyDataset(Xtest,ytest,transforms0)\n",
        "Xallset = np.concatenate([Xtrain,Xtest])\n",
        "yallset = np.concatenate([ytrain,ytest])\n",
        "allset = MyDataset(Xallset,yallset,transforms0)\n",
        "catindex = (yallset == myclasses.index('ネコ'))\n",
        "catset = MyDataset(Xallset[catindex],yallset[catindex],transforms0)\n"
      ],
      "metadata": {
        "id": "1RIIP5f4gRc9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 データローダの作成\n",
        "上で作成したデータセットで、次の３つのデータローダを作成します。\n",
        "1. trainloader    訓練用画像を枚挙するデータローダ\n",
        "2. testloader     テスト用画像を枚挙するデータローダ\n",
        "3. catloader      ネコ画像ばかりを枚挙するデータローダ\n",
        "\n",
        "　[次のセルを実行してください]()  　コードは非表示にしてあります。"
      ],
      "metadata": {
        "id": "n2jlrlyLmsm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　データローダの作成\n",
        "BATCH_SIZE = 8 # バッチサイズ　データ数いくつごとにモデル修正するか\n",
        "WORKERS = 2 # 並列処理するときの並列実行の数\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=WORKERS)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=WORKERS)\n",
        "catloader = DataLoader(catset, batch_size=BATCH_SIZE,\n",
        "                                          shuffle=True, num_workers=WORKERS)"
      ],
      "metadata": {
        "id": "79NKnZXzmYFU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データローダの動作確認\n",
        "\n",
        "　[次のセルを実行してください]() 　コードは非表示にしてあります。"
      ],
      "metadata": {
        "id": "wFInr1BTln6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　データローダの動作確認\n",
        "# 画像を１枚表示する関数\n",
        "def t2np(img):\n",
        "    img = torch.clamp(img / 2 + 0.5, min=0, max=1)     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    return np.transpose(npimg, (1, 2, 0))\n",
        "\n",
        "# データローダからバッチ数分の画像を取り出す。\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# 先頭の画像を表示\n",
        "plt.imshow(t2np(images[0]))\n",
        "\n",
        "# １バッチ分の画像を並べて表示\n",
        "cifar10classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck') # 仮\n",
        "def plotchr(images,labels,tlabels=[],classnames=cifar10classes):\n",
        "    # sns.set_context(\"talk\")   # \"talk\" はタイトルの文字サイズ。　paper <  notebook <  talk <  poster の順にフォントサイズが大きくなる\n",
        "    low = (len(images)-1)//BATCH_SIZE+1\n",
        "    for i,(image,label) in enumerate(zip(images,labels)):\n",
        "        clabel = classnames[label]\n",
        "        image = t2np(image)\n",
        "        plt.subplot(1,BATCH_SIZE,i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        if len(tlabels) > 0:\n",
        "          plt.title(f\"{clabel}/{classnames[tlabels[i]]}\")\n",
        "        else:\n",
        "          plt.title(\"%s\" % clabel)\n",
        "        plt.imshow(image,cmap=plt.cm.gray_r)\n",
        "\n",
        "plt.figure(figsize=(10,4),dpi=100)\n",
        "plotchr(images,labels,tlabels=[],classnames=myclasses)"
      ],
      "metadata": {
        "id": "BvsE_5eF1Sho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 CIFAR10用学習済みモデルで自分の画像データを識別させてみる\n",
        "### (1) モデルの読み込み\n",
        "\n",
        "<font color=red> (注意) ここから後はCIFAR10PyTorch001で作成した学習済みモデルが必要となります。\n",
        "\n",
        "自分のグーグルドライブを開き、マイドライブのCIFAR10 フォルダに cpu_64_model3.pthとgpu_64_model3.pth があるかどうか確認してください。\n",
        "\n",
        "1. 動作環境の確認で 'cpu' と表示されている場合はcpu_64_model3.pth\n",
        "2. 動作環境の確認で 'cuda:0' と表示されている場合gpu_64_model3.pth\n",
        "\n",
        "が必要となります. ない場合は， Caddie においてありますのでダウンロードし， Google Drive の CIFAR10フォルダにアップロードしてください．\n",
        "\n",
        "</font>\n",
        "\n",
        "\n",
        "\n",
        "[次のセルを実行してください]() 　コードは非表示にしてあります。\n",
        "\n"
      ],
      "metadata": {
        "id": "6Emo6b4ngen3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model3 のクラス定義と学習済みモデル model3 の復元\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"   # device side error が出る場合があるので同期を有効にしてみる。\n",
        "\n",
        "# Model3 定義\n",
        "class FReLU(nn.Module):\n",
        "    def __init__(self, in_c, k=3, s=1, p=1):\n",
        "        super().__init__()\n",
        "        self.f_conv = nn.Conv2d(in_c, in_c, kernel_size=k,stride=s, padding=p,groups=in_c)\n",
        "        self.bn = nn.BatchNorm2d(in_c)\n",
        "\n",
        "    def forward(self, x):\n",
        "        tx = self.bn(self.f_conv(x))\n",
        "        out = torch.max(x,tx)\n",
        "        return out\n",
        "\n",
        "class Model3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.n_mid = N_MID\n",
        "        self.conv1 = nn.Conv2d(3,6, 3,padding=1, padding_mode='replicate')\n",
        "        self.frelu = FReLU(6)\n",
        "        self.conv2 = nn.Conv2d(6,16,3, padding=1,padding_mode='replicate')\n",
        "        self.frelu1 = FReLU(16)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv3  = nn.Conv2d(16, self.n_mid, 3, padding=1,padding_mode='replicate')\n",
        "        self.frelu2 = FReLU(self.n_mid)\n",
        "        self.conv4  = nn.Conv2d(self.n_mid, self.n_mid, 3,padding=1, padding_mode='replicate')\n",
        "        self.frelu3 = FReLU(self.n_mid)\n",
        "        self.gavg = nn.AvgPool2d(8) # グローバルアベレージプーリング\n",
        "        self.layer = nn.Linear(self.n_mid, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x) # 3ch -> 6  3x3フィルタで畳み込み 32x32->32x32\n",
        "        x = self.frelu(x)\n",
        "        x = self.conv2(x) # 6ch -> 16  3x3フィルタで畳み込み 32x32 -> 32x32\n",
        "        x = self.frelu1(x)\n",
        "        x = self.pool(x)  # max pooling  2x2  32x32->16x16\n",
        "        x = self.conv3(x) # 16ch -> n_mid ch 3x3フィルタで畳み込み 16x16 -> 16x16\n",
        "        x = self.frelu2(x)\n",
        "        x = self.conv4(x) # n_mid ch -> n_mid ch 3x3フィルタで畳み込み 16x16 -> 16x16\n",
        "        x = self.frelu3(x)\n",
        "        x = self.pool(x)  # max pooling  2x2  16x16->8x8\n",
        "        x = self.gavg(x)  # n_midノード\n",
        "        x = x.view(-1,self.n_mid)\n",
        "        x = self.layer(x) # n_mid->10\n",
        "        return x\n",
        "\n",
        "model3 = Model3()\n",
        "model3.to(device)\n",
        "\n",
        "# 学習済みモデルの重みのセット\n",
        "FNAME = 'model3.pth'\n",
        "DIR = '/content/drive/MyDrive/CIFAR10'\n",
        "GPUPATH = f\"{DIR}/gpu_{N_MID}_{FNAME}\"\n",
        "CPUPATH = f\"{DIR}/cpu_{N_MID}_{FNAME}\"\n",
        "if device.type == 'cuda':\n",
        "    model3.load_state_dict(torch.load(GPUPATH))\n",
        "else:\n",
        "    model3.load_state_dict(torch.load(CPUPATH,map_location=torch.device('cpu')))\n",
        "\n",
        "summary(model3,(3,32,32))\n",
        "\n",
        "import copy\n",
        "backupmodel = copy.deepcopy(model3)"
      ],
      "metadata": {
        "id": "pEQoa7SmiiZB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) CIFAR10のモデルに識別させてみる\n",
        "ためしに、CIFAR10のデータセットで学習させたモデルで自作データセットの認識をさせてみましょう。\n",
        "\n",
        "ネコ画像だけで作成したデータセットのネコ画像を正しくネコと認識できる割合を求めてみます。\n",
        "\n",
        "　[次の２つのセルを続けて実行してください]()"
      ],
      "metadata": {
        "id": "xqwkooqiIbzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　ネコの正解率\n",
        "ncat = 0 # ネコと判定されたデータのカウンタ\n",
        "ndata = 0 # データのカウンタ\n",
        "model3.eval() # 推論モードにスイッチ\n",
        "for data in catloader:\n",
        "  images, labels = data\n",
        "  ndata += len(images)\n",
        "  images = images.to(device)\n",
        "  outputs = (torch.max(model3(images),1)[1]).to('cpu').numpy()\n",
        "  ncat += (outputs == cifar10classes.index('cat')).sum()\n",
        "print(f\"cat 正解率 {100*ncat/ndata:.1f}% ,({ncat}/{ndata})\")"
      ],
      "metadata": {
        "id": "1hUvsEjzEgIK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　識別結果の例　実行するたびに別の結果が表示されます\n",
        "dataiter = iter(catloader)  # 全部ネコ画像のはず\n",
        "plt.figure(figsize=(10,3),dpi=100)\n",
        "images, labels = next(dataiter)\n",
        "images = images.to(device)\n",
        "outputs = model3(images)\n",
        "predicted = torch.max(outputs.data, 1)[1]\n",
        "images = images.to('cpu') if torch.cuda.is_available() else images\n",
        "plotchr(images,predicted,[])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MwKNmNOoZXBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "例として８つだけ画像を表示しています。画像の上のラベルはmodel3 の識別結果です。"
      ],
      "metadata": {
        "id": "rXSkvNMNO1tv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ネコはCIFAR10のカテゴリの中では正解率が相対的に低くなる傾向があります。自分で集めたネコ画像だと正解率はさらに低く出たと思います。検索で集めた画像はネコが中央に大きく写っているとは限らないので正解率が低くなるのは仕方ありません。\n",
        "\n",
        "ネコ以外の画像だとどう認識されるかも試してみましょう。trainloaderがランダムに選んだ8枚で試してみます。もちろん、CIFAR10のカテゴリのいずれかとして認識されてしまいます。\n",
        "\n",
        "　[次のセルを実行してください]() 　　コードは非表示にしてあります。"
      ],
      "metadata": {
        "id": "A29X8yUAW8-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 集めた画像をランダムに識別　何度か繰り返し実行してみましょう\n",
        "dataiter = iter(trainloader)  #\n",
        "plt.figure(figsize=(10,3),dpi=100)\n",
        "images, labels = next(dataiter)\n",
        "images = images.to(device)\n",
        "outputs = model3(images)\n",
        "predicted = torch.max(outputs.data, 1)[1]\n",
        "images = images.to('cpu') if torch.cuda.is_available() else images\n",
        "plotchr(images,predicted,[])"
      ],
      "metadata": {
        "id": "rTSjvaZWSWLS",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[上のセルは実行するたびに異なる画像が出てきます。何度か試してみてください。]()"
      ],
      "metadata": {
        "id": "gc0SkQUOP6w-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ３．自作データセットでのモデルの学習\n",
        "\n",
        "## 3.1 学習用ヘルパー関数の定義\n",
        "\n",
        "　[次のセルを実行してください]() 　コードは非表示にしてあります。"
      ],
      "metadata": {
        "id": "mQwUGbawQQdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　学習用ヘルパー関数\n",
        "# 学習用ヘルパー関数\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter(log_dir=\"./logs\")\n",
        "\n",
        "def train(model, dataloader, optimizer, epochs=1,lastepoch=0,label=\"loss\"):\n",
        "    model.train() # 学習モードにスイッチ\n",
        "    for epoch in range(lastepoch,epochs,1):  # 全データをEPOCH回学習に利用したら終わり\n",
        "        running_loss = 0.0\n",
        "        accuracy = 0\n",
        "        total = 0\n",
        "        nbatch = len(dataloader.dataset)//BATCH_SIZE\n",
        "        ndata = len(dataloader.dataset)\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            # データセットからバッチサイズ個分のデータ[inputs, labels]を取り出す。\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # すべての学習対象パラメータ（結合重み、しきい値）の微係数を０にセット\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward + backward + optimize\n",
        "            outputs = model(images) # 現モデルを使って出力を求める (forward)\n",
        "            predicted = torch.max(model(images),1)[1]\n",
        "            loss = nn.CrossEntropyLoss()(outputs, labels) #  # カテゴリカルクロスエントロピー誤差を計算\n",
        "            loss.backward() # パラメータを変数として誤差を偏微分(backward)\n",
        "            optimizer.step() # 誤差逆伝搬学習　誤差が減る方向にパラメータを修正 (optimize)\n",
        "\n",
        "            # 統計量の出力 epoch 毎に表示\n",
        "            running_loss += loss.item()\n",
        "            accuracy += (predicted == labels).sum().item() # 正解数を積算\n",
        "            total += labels.size(0) # 入力画像数を積算\n",
        "            if i in[nbatch//4-1,nbatch//2-1,3*nbatch/4-1,nbatch-1]:\n",
        "                writer.add_scalar(label+\"loss\", running_loss/total,epoch*ndata+total)\n",
        "                writer.add_scalar(label+\"acc\", accuracy/total,epoch*ndata+total)\n",
        "\n",
        "        print(f'[{epoch + 1}] loss: {running_loss /total:.3f}  acc:{accuracy/total:.3f}  ({accuracy}/{total})')\n",
        "\n",
        "\n",
        "    print('学習完了')\n",
        "\n",
        "# 結果分析用ヘルパー関数\n",
        "# from pandas.compat.numpy import np_datetime64_compat\n",
        "import pandas as pd\n",
        "# クロス集計\n",
        "def recognitionResult(model, dataloader, classes=[]):\n",
        "    model.eval() # 推論モードにスイッチ\n",
        "    ndata = 0 #\n",
        "    NCAT = len(classes)\n",
        "    ct1 = np.zeros((NCAT,NCAT),np.uint16) # 認識結果集計表\n",
        "    for data in dataloader:\n",
        "      images, labels = data\n",
        "      ndata += len(images)\n",
        "      # バッチごとに出力を求める\n",
        "      images = images.to(device)\n",
        "      outputs = torch.max(model(images),1)[1]\n",
        "      for i in range(len(labels)):\n",
        "        ct1[labels[i],outputs[i]] += 1\n",
        "    crossT1 = pd.concat([pd.DataFrame(classes,columns=['正解カテゴリ']),pd.DataFrame(ct1,columns=classes)],axis=1)\n",
        "    crossT1 = pd.concat([crossT1,pd.DataFrame([np.nan if sum(ct1[i])==0 else np.round(1000*crossT1[cat][i]/np.sum(ct1[i]))/10 for i,cat in enumerate(classes)],columns=['正解率'])],axis=1).set_index('正解カテゴリ')\n",
        "\n",
        "    ccount = 0\n",
        "    for i in range(len(classes)):\n",
        "      ccount += ct1[i,i]\n",
        "    print(f\"正解率は{np.round(1000*ccount/ct1.sum())/10}%\")\n",
        "    return crossT1"
      ],
      "metadata": {
        "id": "z_fS3STretAY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 モデル定義\n",
        "CIFAR10で定義した Model3 の出力だけを４つにしたモデル、Model4 を定義します。\n",
        "[次のセルを実行してください]()  \n"
      ],
      "metadata": {
        "id": "aI3PeN50Tv2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "class Model4(Model3):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer = nn.Linear(self.n_mid, 4)   # この部分の出力だけを10から4に変える\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x) # 3ch -> 6  3x3フィルタで畳み込み 32x32->32x32\n",
        "        x = self.frelu(x)\n",
        "        x = self.conv2(x) # 6ch -> 16  3x3フィルタで畳み込み 32x32 -> 32x32\n",
        "        x = self.frelu1(x)\n",
        "        x = self.pool(x)  # max pooling  2x2  32x32->16x16\n",
        "        x = self.conv3(x) # 16ch -> n_mid ch 3x3フィルタで畳み込み 16x16 -> 16x16\n",
        "        x = self.frelu2(x)\n",
        "        x = self.conv4(x) # n_mid ch -> n_mid ch 3x3フィルタで畳み込み 16x16 -> 16x16\n",
        "        x = self.frelu3(x)\n",
        "        x = self.pool(x)  # max pooling  2x2  16x16->8x8\n",
        "        x = self.gavg(x)  # n_midノード\n",
        "        x = x.view(-1,self.n_mid)\n",
        "        x = self.layer(x) # n_mid->10\n",
        "        return x\n",
        "\n",
        "model4 = Model4()\n",
        "model4 = model4.to(device)\n",
        "\n",
        "optimizer4 = optim.Adam(model4.parameters(), lr=0.001) #\n",
        "\n",
        "# モデル概要\n",
        "summary(model4,(3,32,32))"
      ],
      "metadata": {
        "id": "96AUzkj_UVaQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model3との違いは最終層の出力の数だけです。CIFAR-10では10カテゴリだったので最後hあ10ノードでしたが自分で集めが画像は4カテゴリなので４としています。"
      ],
      "metadata": {
        "id": "T9l25p1LbM3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 学習"
      ],
      "metadata": {
        "id": "H5scrQEJbppU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " さっそく学習させてみましょう。  [次のセルを実行してください。]()"
      ],
      "metadata": {
        "id": "xZw4uWaGb3Gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "%%time\n",
        "EPOCH = 20\n",
        "model4 = Model4()\n",
        "model4 = model4.to(device)\n",
        "optimizer4 = optim.Adam(model4.parameters(), lr=0.001) #\n",
        "train(model=model4, optimizer=optimizer4, dataloader=trainloader, epochs=EPOCH, lastepoch=0,label=\"model4\")"
      ],
      "metadata": {
        "id": "CgNUBZRUWXwt",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR10のデータセットと比べてデータ数が圧倒的に少ないので学習はすぐ終わるはずです。"
      ],
      "metadata": {
        "id": "O7uaSU-YcRPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 識別実験\n",
        "\n"
      ],
      "metadata": {
        "id": "QYSNQXGXcrua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " [セルを順に実行していってください。]()"
      ],
      "metadata": {
        "id": "lS25Kcaqc4gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　正解率\n",
        "print(\"訓練画像 -- \",end='')\n",
        "trainct = recognitionResult(model4,trainloader,classes=myclasses)\n",
        "print(\"テスト画像 -- \",end='')\n",
        "testct = recognitionResult(model4,testloader,classes=myclasses)\n",
        "#trainct"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Rgz8Q518WyDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 訓練用画像の識別結果のクロス集計\n",
        "trainct"
      ],
      "metadata": {
        "cellView": "form",
        "id": "tFm7hmJxd_IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title テスト用画像の識別結果のクロス集計\n",
        "testct"
      ],
      "metadata": {
        "cellView": "form",
        "id": "J5QfDWJfdpPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "どんな画像を間違ったかいくつか見てみましょう。　次のセルを実行してください。"
      ],
      "metadata": {
        "id": "M78xAjwmeNhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 誤識別例\n",
        "n = 0\n",
        "dataiter = iter(testloader)\n",
        "errs = []\n",
        "el = []\n",
        "tl = []\n",
        "while n < 8:\n",
        "  images, labels = next(dataiter)\n",
        "  images = images.to(device)\n",
        "  outputs = model4(images)\n",
        "  predicted = torch.max(outputs.data, 1)[1]\n",
        "  for i,l in enumerate(labels):\n",
        "    if l != predicted[i]:\n",
        "      errs.append(images[i].to('cpu'))\n",
        "      tl.append(l)\n",
        "      el.append(predicted[i])\n",
        "      n += 1\n",
        "      img = np.transpose(images[i].to('cpu'),(1,2,0))\n",
        "      img = (img+1)/2\n",
        "\n",
        "plt.figure(figsize=(12,3),dpi=100)\n",
        "plotchr(errs[:8],el[:8],tl[:8],myclasses)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e9bdjGfLegoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上のセルを何度か実行してみましょう。間違いの傾向があるでしょうか？　間違った理由が創造できるでしょうか？"
      ],
      "metadata": {
        "id": "9KlGRotHj9oL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "学習の様子をグラフで確認してみましょう。 [次のセルを実行してください]()"
      ],
      "metadata": {
        "id": "c4KAtJngk0X0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "uY2qrqAzkp3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "グラフを見ると、もっと学習すると正解率は上がりそうです。30エポック追加学習してみましょう。  \n",
        "　[次のセルを実行してください]()"
      ],
      "metadata": {
        "id": "S6ADmmwhlC9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model=model4, optimizer=optimizer4, dataloader=trainloader, epochs=50, lastepoch=20,label=\"model4\")"
      ],
      "metadata": {
        "id": "2oAyltvalSdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "正解率が向上したかどうか確認してみましょう。 [次のセルを実行してください]()"
      ],
      "metadata": {
        "id": "M-WI03hZmCT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title　追加学習後の正解率\n",
        "print(\"訓練画像 -- \",end='')\n",
        "trainct = recognitionResult(model4,trainloader,classes=myclasses)\n",
        "print(\"テスト画像 -- \",end='')\n",
        "testct = recognitionResult(model4,testloader,classes=myclasses)\n",
        "#trainct"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N_0AWc4pcUg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model4 は 50エポックぐらいで訓練画像についてはほぼ100％正解するようになります。\n",
        "\n",
        "訓練画像は正解のわかっている画像なので、100％正解でも驚くに値しません。正解を丸覚えしてしまえば100％正解できるからです。深層学習は丸覚えではありませんが、100％正解というのは過学習を疑わないといけません。"
      ],
      "metadata": {
        "id": "oOwhbQEomZ3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ４. 転移学習\n",
        "## 4.1 モデルの流用\n",
        "\n",
        "ある認識問題用に作られた学習済みモデルを他の認識問題に流用することを**転移学習**と呼びます。\n",
        "\n",
        "同じモデル構造を使ったとしても、識別対象が変われば注目すべき特徴、取り出すべき特徴量は変わるはずですし、モデルの最適なパラメータが同じであるわけはありませんが、パラメータをランダムな初期値で始めて学習を進めるより、別の問題で成功したパラメータ値を初期値ととした方が効率的にパラメータの最適化ができることが経験的にわかっています。\n",
        "\n",
        "これは、問題、つまり識別対象が違っても、中間層までで取り出すべき特徴は共通しているということを意味します。画像処理的に言えば、画像に基づいて何らかの判断を下すのであれば、問題に限らず初期段階で画像を加工して取り出すべき特徴は変わらない、ある問題で役に立った特徴や処理は別の問題でも有用だ、ということを意味しています。\n",
        "\n",
        "CIFAR10PyTorch001で保存したModel３の学習済みモデルを使って転移学習を試みます。\n",
        "\n",
        "　[次のセルを実行してください]()\n"
      ],
      "metadata": {
        "id": "2eJ_u7EyhfWD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# model3の最後の畳み込み層を除いてパラメータを固定する\n",
        "for name, param in model3.named_parameters():\n",
        "  if 'frelu3' in name or 'conv4' in name:\n",
        "    param.requres_grad = True\n",
        "    print(name)\n",
        "  else:\n",
        "    param.requres_grad = False\n",
        "# model3 の改造　最終層を出力数４に置き換える。\n",
        "model3.layer = (nn.Linear(N_MID,4)).to(device)  # 出力層を出力４の全結合層に置き換える。\n",
        "from torchsummary import summary\n",
        "summary(model3,(3,32,32))"
      ],
      "metadata": {
        "id": "5XIDNsWI3Ji3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上のプログラムで、学習済みモデル model3 のパラメータを、最後の畳み込み層を除き、固定し、最後の層を出力数４の全結合層に置き換えています。\n",
        "\n",
        "結果として学習の対象は最後の畳み込み層と出力層だけになります。\n",
        "\n",
        "このモデルを自作データで学習させてみましょう。　　　[次のセルを実行してください]()"
      ],
      "metadata": {
        "id": "_7nCCQNdpvSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "optimizer3 = optim.Adam(model3.parameters(), lr=0.001) #\n",
        "train(model=model3, optimizer=optimizer3, dataloader=trainloader, epochs=20, lastepoch=0,label=\"model3\")"
      ],
      "metadata": {
        "id": "floGePVx0mdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20エポック学習させただけで、ほぼ収束します。  [次のセルを実行してください]()"
      ],
      "metadata": {
        "id": "CeBTRiHjrNvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainct3 = recognitionResult(model3, trainloader,classes=myclasses)\n",
        "testct3 =  recognitionResult(model3, testloader,classes=myclasses)"
      ],
      "metadata": {
        "id": "o8z7lN3IKkPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練データでの正解率\n",
        "trainct3"
      ],
      "metadata": {
        "id": "LPBB6VViKs5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# テストデータでの正解率\n",
        "testct3"
      ],
      "metadata": {
        "id": "jAxSGOwONx0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title mode3 転移モデルの誤識別例\n",
        "n = 0\n",
        "dataiter = iter(testloader)\n",
        "errs = []\n",
        "el = []\n",
        "tl = []\n",
        "while n < 8:\n",
        "  images, labels = next(dataiter)\n",
        "  images = images.to(device)\n",
        "  outputs = model3(images)\n",
        "  predicted = torch.max(outputs.data, 1)[1]\n",
        "  for i,l in enumerate(labels):\n",
        "    if l != predicted[i]:\n",
        "      errs.append(images[i].to('cpu'))\n",
        "      tl.append(l)\n",
        "      el.append(predicted[i])\n",
        "      n += 1\n",
        "      img = np.transpose(images[i].to('cpu'),(1,2,0))\n",
        "      img = (img+1)/2\n",
        "\n",
        "plt.figure(figsize=(12,3),dpi=100)\n",
        "plotchr(errs[:8],el[:8],tl[:8],myclasses)"
      ],
      "metadata": {
        "id": "8M5CObljHYFz",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "2bgy2VRlF5JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Z51wnnM2psH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 課題\n",
        "\n",
        "1. 結果について考察してください．（例えば，他のカテゴリと比べて正解が多いカテゴリや逆に間違いが多いカテゴリなど，気づいたことや，その理由など．）\n",
        "\n",
        "余裕があれば次のような追加実験をしましょう．\n",
        "\n",
        "2. 同じ実験を何度か繰り返し，同じ傾向がみられるかどうか検証する．\n",
        "3. エポック数をもっと増やして正解率が上がるかどうか調べる。\n",
        "4. 別のカテゴリで実験してみる。\n",
        "5. もっとカテゴリを増やして実験してみる．\n"
      ],
      "metadata": {
        "id": "j6MkXAV6DoKo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kfO7RBb3D0Lu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}